{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "import psutil\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = str(multiprocessing.cpu_count())\n",
    "os.environ['MKL_NUM_THREADS'] = str(multiprocessing.cpu_count()) \n",
    "os.environ['NUMEXPR_NUM_THREADS'] = str(multiprocessing.cpu_count())\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'  \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    multiprocessing.set_start_method('spawn', force=True)\n",
    "except RuntimeError:\n",
    "    pass\n",
    "\n",
    "def check_system_info():\n",
    "    print(\"系统信息检测\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    cpu_count = multiprocessing.cpu_count()\n",
    "    cpu_freq = psutil.cpu_freq()\n",
    "    memory = psutil.virtual_memory()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        import torch\n",
    "        torch.cuda.is_available():\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "        \n",
    "        print(\"未检测到CUDA GPU，将使用CPU模式\")\n",
    "    except:\n",
    "        print(\"PyTorch未安装，稍后自动安装\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "\n",
    "check_system_info()\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"安装系统依赖\"\"\"\n",
    "    required_packages = [\n",
    "        'torch>=2.0.0',\n",
    "        'transformers>=4.35.0', \n",
    "        'peft>=0.6.0',\n",
    "        'sentence-transformers>=2.2.0',\n",
    "        'faiss-cpu>=1.7.4',\n",
    "        'pandas>=1.5.0',\n",
    "        'numpy>=1.21.0',\n",
    "        'scikit-learn>=1.3.0',\n",
    "        'matplotlib>=3.5.0',\n",
    "        'seaborn>=0.11.0',\n",
    "        'tqdm>=4.64.0',\n",
    "        'accelerate>=0.24.0',\n",
    "        'openpyxl>=3.0.0', \n",
    "        'xlrd>=2.0.0'     \n",
    "    ]\n",
    "    \n",
    "    print(\"\\n检查并安装依赖包...\")\n",
    "    for package in required_packages:\n",
    "        try:\n",
    "            __import__(package.split('>=')[0].split('==')[0])\n",
    "        except ImportError:\n",
    "            print(f\"安装 {package}\")\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "\n",
    "install_requirements()\n",
    "\n",
    "print(\"环境检测完成！\")\n",
    "print(f\"已配置 {multiprocessing.cpu_count()} 线程并行处理\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "import multiprocessing\n",
    "import psutil\n",
    "\n",
    "CPU_COUNT = multiprocessing.cpu_count()\n",
    "MEMORY_GB = psutil.virtual_memory().total / (1024**3)\n",
    "GPU_AVAILABLE = torch.cuda.is_available()\n",
    "GPU_MEMORY_GB = torch.cuda.get_device_properties(0).total_memory / (1024**3) if GPU_AVAILABLE else 0\n",
    "\n",
    "\n",
    "CONFIG_TYPE = \"balanced\"\n",
    "\n",
    "LINUX_CONFIG = {\n",
    "    # 基础配置\n",
    "    \"config_type\": CONFIG_TYPE,\n",
    "    \"use_gpu\": GPU_AVAILABLE,\n",
    "    \"device\": \"cuda\" if GPU_AVAILABLE else \"cpu\",\n",
    "    \n",
    "    # 多线程配置\n",
    "    \"num_workers\": min(CPU_COUNT, 8),  # 限制最大线程数避免过载\n",
    "    \"prefetch_factor\": 2,\n",
    "    \"pin_memory\": GPU_AVAILABLE,\n",
    "    \"thread_pool_size\": CPU_COUNT // 2,\n",
    "    \"process_pool_size\": min(CPU_COUNT // 2, 4),\n",
    "    \n",
    "    # 模型配置 \n",
    "    \"model_configs\": {\n",
    "        \"balanced\": {\n",
    "            \"model_name\": \"ShengbinYue/LawLLM-7B\", \n",
    "            \"max_length\": 1024,\n",
    "            \"batch_size\": 2,\n",
    "            \"use_4bit\": True,\n",
    "            \"cpu_offload\": False,\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    # RAG配置\n",
    "    \"rag_config\": {\n",
    "        \"embedding_model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        \"top_k\": 5,\n",
    "        \"similarity_threshold\": 0.7,\n",
    "        \"chunk_size\": 256,\n",
    "        \"chunk_overlap\": 50,\n",
    "        \"index_type\": \"faiss\",\n",
    "    },\n",
    "    \n",
    "    # LoRA配置\n",
    "        \"lora_config\": {\n",
    "        \"r\": 8,\n",
    "        \"lora_alpha\": 32,\n",
    "        \"lora_dropout\": 0.1,\n",
    "        \"target_modules\": [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "        \"bias\": \"none\",\n",
    "        \"task_type\": \"CAUSAL_LM\",\n",
    "    },\n",
    "     \n",
    "     # 训练配置\n",
    "    \"training_config\": {\n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"num_epochs\": 2,\n",
    "        \"warmup_steps\": 50,\n",
    "        \"gradient_accumulation_steps\": 2,\n",
    "        \"dataloader_num_workers\": 0,\n",
    "        \"fp16\": GPU_AVAILABLE,\n",
    "        \"gradient_checkpointing\": True,\n",
    "    }\n",
    "}\n",
    "\n",
    "# 显示当前配置\n",
    "current_config = LINUX_CONFIG[\"model_configs\"][CONFIG_TYPE]\n",
    "print(f\"\\n已选择配置: {CONFIG_TYPE}\")\n",
    "print(f\"模型: {current_config['model_name']}\")\n",
    "print(f\"批处理大小: {current_config['batch_size']}\")\n",
    "print(f\"最大长度: {current_config['max_length']}\")\n",
    "print(f\"多线程数: {LINUX_CONFIG['num_workers']}\")\n",
    "print(f\"4bit量化: {current_config['use_4bit']}\")\n",
    "print(f\"CPU卸载: {current_config['cpu_offload']}\")\n",
    "\n",
    "THREAD_POOL = ThreadPoolExecutor(max_workers=LINUX_CONFIG['thread_pool_size'])\n",
    "PROCESS_POOL = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "from concurrent.futures import as_completed\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "class LegalDataProcessor:\n",
    "    \n",
    "    def __init__(self, config=LINUX_CONFIG):\n",
    "        self.config = config\n",
    "        self.data = None\n",
    "        self.processed_data = None\n",
    "        \n",
    "    def _create_sample_data(self):\n",
    "        sample_data = {\n",
    "            '纠纷条款原文': [\"公司有权根据经营需要调整员工的工作岗位。\", \"员工应保证24小时随叫随到，否则视为旷工。\"],\n",
    "            '条款缺陷分析': [\"该条款过于宽泛，可能被认定为无效。未明确调整岗位的合理性、协商程序等，容易引发争议。\", \"该要求严重违反劳动法关于工作时间的规定，侵害员工休息权，属于无效条款。\"],\n",
    "            '违约/纠纷案例': [\"员工因拒绝公司无理由调岗被辞退，后起诉公司，法院判决公司违法解除劳动合同。\", \"某程序员因拒绝半夜到公司处理非紧急事务被辞退，仲裁裁定公司支付赔偿金。\"],\n",
    "            '判决结果': [\"法院认定公司调岗不具有合理性，属于违法解除，应支付赔偿金。\", \"仲裁委认定公司要求24小时待命违法，构成违法解除。\"],\n",
    "            '法律依据': [\"《劳动合同法》第三十五条、第四十条\", \"《劳动法》第三十八条、第四十一条\"]\n",
    "        }\n",
    "        return pd.DataFrame(sample_data)\n",
    "\n",
    "    def load_data(self, file_path=\"./data.xlsx\", sheet_name=None):\n",
    "        print(\"加载劳动合规数据集...\")\n",
    "        \n",
    "        try:\n",
    "            if file_path.endswith('.xlsx') or file_path.endswith('.xls'):\n",
    "                print(f\"检测到Excel文件: {file_path}\")\n",
    "                \n",
    "                if sheet_name is None:\n",
    "                    excel_file = pd.ExcelFile(file_path)\n",
    "                    sheet_names = excel_file.sheet_names\n",
    "                    print(f\"发现工作表: {sheet_names}\")\n",
    "                    \n",
    "                    # 选择第一个工作表，或者包含\"data\"关键词的工作表\n",
    "                    for name in sheet_names:\n",
    "                        if 'data' in name.lower() or '数据' in name or '案例' in name:\n",
    "                            sheet_name = name\n",
    "                            break\n",
    "                    \n",
    "                    if sheet_name is None:\n",
    "                        sheet_name = sheet_names[0]  # 默认使用第一个工作表\n",
    "                    \n",
    "                    print(f\"使用工作表: {sheet_name}\")\n",
    "                \n",
    "                # 读取Excel文件\n",
    "                self.data = pd.read_excel(\n",
    "                    file_path, \n",
    "                    sheet_name=sheet_name,\n",
    "                    engine='openpyxl'  # 使用openpyxl引擎\n",
    "                )\n",
    "                \n",
    "            elif file_path.endswith('.csv'):\n",
    "                # CSV文件处理（兼容性保留）\n",
    "                print(f\"检测到CSV文件: {file_path}\")\n",
    "                self.data = pd.read_csv(file_path)\n",
    "            else:\n",
    "                raise ValueError(f\"不支持的文件格式: {file_path}\")\n",
    "            \n",
    "            print(f\"成功加载 {len(self.data)} 条劳动合规案例\")\n",
    "            \n",
    "            # 显示数据概览\n",
    "            print(\"\\n数据集概览:\")\n",
    "            print(f\"列名: {list(self.data.columns)}\")\n",
    "            print(f\"数据形状: {self.data.shape}\")\n",
    "            \n",
    "            # 检查关键列\n",
    "            required_columns = ['纠纷条款原文', '条款缺陷分析', '违约/纠纷案例', '判决结果', '法律依据']\n",
    "            missing_columns = [col for col in required_columns if col not in self.data.columns]\n",
    "            \n",
    "            if missing_columns:\n",
    "                print(f\"缺失列: {missing_columns}\")\n",
    "            else:\n",
    "                print(\"所有必需列都存在\")\n",
    "                \n",
    "            return self.data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"数据加载失败: {e}\")\n",
    "            print(\"请检查文件路径和格式:\")\n",
    "            print(\"   - Excel文件: ./data.xlsx\")  \n",
    "            print(\"   - CSV文件: ./data.csv\")\n",
    "            print(\"   - 确保文件包含必要的列: 纠纷条款原文、条款缺陷分析、违约/纠纷案例、判决结果、法律依据\")\n",
    "            # 创建示例数据用于演示\n",
    "            self.data = self._create_sample_data()\n",
    "            return self.data\n",
    "    \n",
    "    def analyze_excel_structure(self, file_path=\"./data.xlsx\"):\n",
    "        \"\"\"分析Excel文件结构\"\"\"\n",
    "        try:\n",
    "            print(f\"分析Excel文件结构: {file_path}\")\n",
    "            \n",
    "            # 读取Excel文件信息\n",
    "            excel_file = pd.ExcelFile(file_path)\n",
    "            sheet_names = excel_file.sheet_names\n",
    "            \n",
    "            print(f\"工作表数量: {len(sheet_names)}\")\n",
    "            \n",
    "            # 分析每个工作表\n",
    "            for i, sheet_name in enumerate(sheet_names):\n",
    "                print(f\"\\n工作表 {i+1}: {sheet_name}\")\n",
    "                \n",
    "                # 读取前几行数据\n",
    "                df_preview = pd.read_excel(\n",
    "                    file_path, \n",
    "                    sheet_name=sheet_name,\n",
    "                    nrows=3,  # 只读取前3行用于预览\n",
    "                    engine='openpyxl'\n",
    "                )\n",
    "                \n",
    "                print(f\"  形状: {df_preview.shape}\")\n",
    "                print(f\"  列名: {list(df_preview.columns)}\")\n",
    "                \n",
    "                # 检查是否包含所需列\n",
    "                required_columns = ['纠纷条款原文', '条款缺陷分析', '违约/纠纷案例', '判决结果', '法律依据']\n",
    "                matching_columns = [col for col in required_columns if col in df_preview.columns]\n",
    "                \n",
    "                if matching_columns:\n",
    "                    print(f\"   匹配列: {matching_columns}\")\n",
    "                    if len(matching_columns) >= 3:\n",
    "                        print(f\"   推荐使用此工作表\")\n",
    "                else:\n",
    "                    print(f\"   未找到标准列名\")\n",
    "                    \n",
    "                # 显示数据预览\n",
    "                if not df_preview.empty:\n",
    "                    print(f\"   数据预览:\")\n",
    "                    for col in df_preview.columns[:3]:  # 显示前3列\n",
    "                        sample_value = str(df_preview[col].iloc[0])[:30] if not pd.isna(df_preview[col].iloc[0]) else \"空值\"\n",
    "                        print(f\"      {col}: {sample_value}...\")\n",
    "            \n",
    "            return sheet_names\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Excel文件分析失败: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"文本清洗\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # 移除多余空白字符\n",
    "        text = re.sub(r'\\s+', ' ', str(text))\n",
    "        # 移除特殊字符但保留中文标点\n",
    "        text = re.sub(r'[^\\u4e00-\\u9fff\\u3000-\\u303f\\uff00-\\uffef\\w\\s.,;:!?()]', '', text)\n",
    "        return text.strip()\n",
    "    \n",
    "    def process_data_parallel(self):\n",
    "        \"\"\"多线程并行处理数据\"\"\"\n",
    "        print(\"\\n开始多线程数据预处理...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # 定义处理函数\n",
    "        def process_row(row_data):\n",
    "            idx, row = row_data\n",
    "            processed_row = {}\n",
    "            \n",
    "            for col in self.data.columns:\n",
    "                processed_row[col] = self.clean_text(row[col])\n",
    "            \n",
    "            # 创建组合字段用于RAG\n",
    "            processed_row['combined_text'] = f\"\"\"\n",
    "            条款原文: {processed_row.get('纠纷条款原文', '')}\n",
    "            缺陷分析: {processed_row.get('条款缺陷分析', '')}\n",
    "            相关案例: {processed_row.get('违约/纠纷案例', '')}\n",
    "            判决结果: {processed_row.get('判决结果', '')}\n",
    "            法律依据: {processed_row.get('法律依据', '')}\n",
    "            \"\"\".strip()\n",
    "            \n",
    "            return idx, processed_row\n",
    "        \n",
    "        # 多线程处理\n",
    "        futures = []\n",
    "        with THREAD_POOL as executor:\n",
    "            for idx, row in self.data.iterrows():\n",
    "                future = executor.submit(process_row, (idx, row))\n",
    "                futures.append(future)\n",
    "        \n",
    "        # 收集结果并显示进度条\n",
    "        processed_rows = {}\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"数据预处理\"):\n",
    "            idx, processed_row = future.result()\n",
    "            processed_rows[idx] = processed_row\n",
    "        \n",
    "        # 转换为DataFrame\n",
    "        self.processed_data = pd.DataFrame.from_dict(processed_rows, orient='index')\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        print(f\"数据预处理完成，用时 {processing_time:.2f} 秒\")\n",
    "        print(f\"处理了 {len(self.processed_data)} 条记录\")\n",
    "        \n",
    "        return self.processed_data\n",
    "    \n",
    "    def get_training_data(self):\n",
    "        \"\"\"获取LoRA训练数据\"\"\"\n",
    "        if self.processed_data is None:\n",
    "            self.process_data_parallel()\n",
    "        \n",
    "        training_data = []\n",
    "        \n",
    "        for _, row in self.processed_data.iterrows():\n",
    "            # 构造训练样本\n",
    "            input_text = f\"请分析以下劳动合同条款的合规风险：\\n{row['纠纷条款原文']}\"\n",
    "            \n",
    "            output_text = f\"\"\"\n",
    "条款缺陷分析：{row['条款缺陷分析']}\n",
    "\n",
    "相关案例：{row['违约/纠纷案例']}\n",
    "\n",
    "判决结果：{row['判决结果']}\n",
    "\n",
    "法律依据：{row['法律依据']}\n",
    "            \"\"\".strip()\n",
    "            \n",
    "            training_data.append({\n",
    "                'input': input_text,\n",
    "                'output': output_text,\n",
    "                'combined': row['combined_text']\n",
    "            })\n",
    "        \n",
    "        return training_data\n",
    "\n",
    "# 初始化数据处理器\n",
    "data_processor = LegalDataProcessor()\n",
    "\n",
    "# Excel文件结构分析（可选）\n",
    "print(\"首先分析Excel文件结构...\")\n",
    "try:\n",
    "    # 尝试分析Excel文件\n",
    "    excel_sheets = data_processor.analyze_excel_structure(\"./data.xlsx\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "except:\n",
    "    print(\"Excel文件分析跳过，将直接尝试加载数据\")\n",
    "\n",
    "# 加载和处理数据\n",
    "print(\"\\n开始加载劳动合规数据...\")\n",
    "legal_data = data_processor.load_data(\"./data.xlsx\")  # 改为Excel文件\n",
    "\n",
    "# 数据清洗和预处理\n",
    "processed_data = data_processor.process_data_parallel()\n",
    "\n",
    "# 准备训练数据\n",
    "training_data = data_processor.get_training_data()\n",
    "\n",
    "print(f\"\\n训练数据准备完成: {len(training_data)} 个样本\")\n",
    "print(\"数据预处理阶段完成！\")\n",
    "\n",
    "# 显示数据统计信息\n",
    "if legal_data is not None and not legal_data.empty:\n",
    "    print(f\"\\n数据集统计:\")\n",
    "    print(f\"   总样本数: {len(legal_data)}\")\n",
    "    print(f\"   列数: {len(legal_data.columns)}\")\n",
    "    print(f\"   数据列: {list(legal_data.columns)}\")\n",
    "    \n",
    "    # 检查数据完整性\n",
    "    missing_data = legal_data.isnull().sum()\n",
    "    if missing_data.sum() > 0:\n",
    "        print(f\"   缺失数据统计:\")\n",
    "        for col, missing_count in missing_data.items():\n",
    "            if missing_count > 0:\n",
    "                print(f\"      {col}: {missing_count} 个缺失值\")\n",
    "    else:\n",
    "        print(f\"   数据完整，无缺失值\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoConfig\n",
    "import gc\n",
    "\n",
    "try:\n",
    "    import faiss\n",
    "    FAISS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    FAISS_AVAILABLE = False\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class LegalRAGSystem:\n",
    "    \n",
    "    def __init__(self, config=LINUX_CONFIG):\n",
    "        self.config = config\n",
    "        self.embedding_model = None\n",
    "        self.knowledge_base = []\n",
    "        self.embeddings = None\n",
    "        self.index = None\n",
    "        \n",
    "    def load_embedding_model(self):\n",
    "        \"\"\"加载嵌入模型\"\"\"\n",
    "        print(\"加载嵌入模型...\")\n",
    "        \n",
    "        model_name = self.config['rag_config']['embedding_model']\n",
    "        \n",
    "        try:\n",
    "            # 设置多线程\n",
    "            self.embedding_model = SentenceTransformer(\n",
    "                model_name,\n",
    "                device=self.config['device']\n",
    "            )\n",
    "            \n",
    "            # 设置编码池大小（如果支持）\n",
    "            if hasattr(self.embedding_model, 'pool'):\n",
    "                try:\n",
    "                    # 尝试设置线程池大小\n",
    "                    import torch\n",
    "                    torch.set_num_threads(self.config['num_workers'])\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            print(f\"嵌入模型加载完成: {model_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"模型加载失败: {e}\")\n",
    "            print(\"尝试加载备用模型...\")\n",
    "            self.embedding_model = SentenceTransformer(\n",
    "                'all-MiniLM-L6-v2',\n",
    "                device='cpu'\n",
    "            )\n",
    "            print(\"备用模型加载完成\")\n",
    "    \n",
    "    def build_knowledge_base(self, processed_data):\n",
    "        \"\"\"多线程构建知识库\"\"\"\n",
    "        print(\"\\n构建法律知识库...\")\n",
    "        \n",
    "        if self.embedding_model is None:\n",
    "            self.load_embedding_model()\n",
    "        \n",
    "        # 构建知识条目\n",
    "        self.knowledge_base = []\n",
    "        \n",
    "        for idx, row in processed_data.iterrows():\n",
    "            # 分类存储不同类型的知识\n",
    "            knowledge_items = [\n",
    "                {\n",
    "                    'type': '条款分析',\n",
    "                    'content': f\"条款: {row['纠纷条款原文']}\\n分析: {row['条款缺陷分析']}\",\n",
    "                    'metadata': {\n",
    "                        'source_id': idx,\n",
    "                        'category': '条款分析',\n",
    "                        'original_clause': row['纠纷条款原文']\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'type': '案例',\n",
    "                    'content': f\"案例: {row['违约/纠纷案例']}\\n判决: {row['判决结果']}\",\n",
    "                    'metadata': {\n",
    "                        'source_id': idx,\n",
    "                        'category': '案例',\n",
    "                        'legal_basis': row['法律依据']\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'type': '法律依据',\n",
    "                    'content': f\"法条: {row['法律依据']}\\n适用场景: {row['纠纷条款原文']}\",\n",
    "                    'metadata': {\n",
    "                        'source_id': idx,\n",
    "                        'category': '法律依据',\n",
    "                        'law_article': row['法律依据']\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            self.knowledge_base.extend(knowledge_items)\n",
    "        \n",
    "        print(f\"知识库构建完成: {len(self.knowledge_base)} 个知识条目\")\n",
    "        \n",
    "        # 生成嵌入向量\n",
    "        self._generate_embeddings()\n",
    "        \n",
    "        # 构建FAISS索引\n",
    "        self._build_faiss_index()\n",
    "        \n",
    "        return self.knowledge_base\n",
    "    \n",
    "    def _generate_embeddings(self):\n",
    "        \"\"\"生成嵌入向量 - 批量多线程处理\"\"\"\n",
    "        print(\"生成嵌入向量...\")\n",
    "        \n",
    "        # 提取文本内容\n",
    "        texts = [item['content'] for item in self.knowledge_base]\n",
    "        \n",
    "        # 批量编码 - 利用多线程\n",
    "        print(\"使用多线程批量编码...\")\n",
    "        \n",
    "        batch_size = 32  # 批量大小\n",
    "        all_embeddings = []\n",
    "        \n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=\"生成嵌入\"):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            \n",
    "            # 使用多线程编码\n",
    "            batch_embeddings = self.embedding_model.encode(\n",
    "                batch_texts,\n",
    "                batch_size=batch_size,\n",
    "                show_progress_bar=False,\n",
    "                convert_to_numpy=True,\n",
    "                normalize_embeddings=True,  # 归一化以便相似度计算\n",
    "                device=self.config['device']  # 确保使用正确的设备\n",
    "            )\n",
    "            \n",
    "            all_embeddings.append(batch_embeddings)\n",
    "        \n",
    "        # 合并所有嵌入\n",
    "        self.embeddings = np.vstack(all_embeddings)\n",
    "        \n",
    "        print(f\"嵌入向量生成完成: {self.embeddings.shape}\")\n",
    "        \n",
    "        # 释放内存\n",
    "        gc.collect()\n",
    "    \n",
    "    def _build_faiss_index(self):\n",
    "        \"\"\"构建向量索引\"\"\"\n",
    "        if FAISS_AVAILABLE:\n",
    "            print(\"构建FAISS向量索引...\")\n",
    "            \n",
    "            # 创建FAISS索引\n",
    "            dimension = self.embeddings.shape[1]\n",
    "            \n",
    "            # 小数据集使用精确搜索\n",
    "            self.index = faiss.IndexFlatIP(dimension)  # 内积索引（余弦相似度）\n",
    "                \n",
    "            # 训练索引\n",
    "            self.index.train(self.embeddings.astype('float32'))\n",
    "            \n",
    "            # 添加向量到索引\n",
    "            self.index.add(self.embeddings.astype('float32'))\n",
    "            \n",
    "            print(f\"FAISS索引构建完成: {self.index.ntotal} 个向量\")\n",
    "        else:\n",
    "            print(\"使用sklearn进行向量检索...\")\n",
    "            # 不使用FAISS时，直接使用numpy数组\n",
    "            self.index = None\n",
    "            print(f\"sklearn检索准备完成: {len(self.embeddings)} 个向量\")\n",
    "    \n",
    "    def search(self, query: str, top_k: int = None) -> List[Dict]:\n",
    "        \"\"\"搜索相关知识\"\"\"\n",
    "        if top_k is None:\n",
    "            top_k = self.config['rag_config']['top_k']\n",
    "        \n",
    "        # 编码查询\n",
    "        query_embedding = self.embedding_model.encode(\n",
    "            [query], \n",
    "            normalize_embeddings=True,\n",
    "            convert_to_numpy=True,\n",
    "            device=self.config['device']\n",
    "        )\n",
    "        \n",
    "        if FAISS_AVAILABLE and self.index is not None:\n",
    "            # 使用FAISS搜索\n",
    "            scores, indices = self.index.search(\n",
    "                query_embedding.astype('float32'), \n",
    "                top_k\n",
    "            )\n",
    "            score_idx_pairs = list(zip(scores[0], indices[0]))\n",
    "        else:\n",
    "            # 使用sklearn进行相似度搜索\n",
    "            similarities = cosine_similarity(\n",
    "                query_embedding.reshape(1, -1), \n",
    "                self.embeddings\n",
    "            )[0]\n",
    "            \n",
    "            # 获取top_k个最相似的索引\n",
    "            top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "            top_scores = similarities[top_indices]\n",
    "            \n",
    "            score_idx_pairs = list(zip(top_scores, top_indices))\n",
    "        \n",
    "        # 整理结果\n",
    "        results = []\n",
    "        for score, idx in score_idx_pairs:\n",
    "            if score > self.config['rag_config']['similarity_threshold']:\n",
    "                result = {\n",
    "                    'content': self.knowledge_base[idx]['content'],\n",
    "                    'metadata': self.knowledge_base[idx]['metadata'],\n",
    "                    'score': float(score),\n",
    "                    'type': self.knowledge_base[idx]['type']\n",
    "                }\n",
    "                results.append(result)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_index(self, path=\"legal_rag_index\"):\n",
    "        \"\"\"保存索引和知识库\"\"\"\n",
    "        print(f\"保存RAG索引到 {path}...\")\n",
    "        \n",
    "        # 保存FAISS索引（如果有）\n",
    "        if FAISS_AVAILABLE and self.index is not None:\n",
    "            faiss.write_index(self.index, f\"{path}_faiss.index\")\n",
    "        \n",
    "        # 保存知识库和元数据\n",
    "        with open(f\"{path}_knowledge.pkl\", 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'knowledge_base': self.knowledge_base,\n",
    "                'config': self.config,\n",
    "                'faiss_available': FAISS_AVAILABLE\n",
    "            }, f)\n",
    "        \n",
    "        # 保存嵌入向量\n",
    "        np.save(f\"{path}_embeddings.npy\", self.embeddings)\n",
    "        \n",
    "        print(\"RAG索引保存完成\")\n",
    "    \n",
    "    def load_index(self, path=\"legal_rag_index\"):\n",
    "        \"\"\"加载索引和知识库\"\"\"\n",
    "        print(f\"从 {path} 加载RAG索引...\")\n",
    "        \n",
    "        try:\n",
    "            # 加载知识库\n",
    "            with open(f\"{path}_knowledge.pkl\", 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                self.knowledge_base = data['knowledge_base']\n",
    "                saved_faiss_available = data.get('faiss_available', True)\n",
    "            \n",
    "            # 加载嵌入向量\n",
    "            self.embeddings = np.load(f\"{path}_embeddings.npy\")\n",
    "            \n",
    "            # 加载FAISS索引（如果可用且存在）\n",
    "            if FAISS_AVAILABLE and saved_faiss_available:\n",
    "                try:\n",
    "                    self.index = faiss.read_index(f\"{path}_faiss.index\")\n",
    "                    print(\"FAISS索引加载完成\")\n",
    "                except:\n",
    "                    print(\"FAISS索引文件不存在，将使用sklearn\")\n",
    "                    self.index = None\n",
    "            else:\n",
    "                print(\"使用sklearn进行向量搜索\")\n",
    "                self.index = None\n",
    "            \n",
    "            print(\"RAG索引加载完成\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"索引加载失败: {e}\")\n",
    "            return False\n",
    "\n",
    "# 初始化RAG系统\n",
    "rag_system = LegalRAGSystem()\n",
    "\n",
    "# 构建知识库\n",
    "knowledge_base = rag_system.build_knowledge_base(processed_data)\n",
    "\n",
    "# 保存索引以供后续使用\n",
    "rag_system.save_index(\"legal_rag_index\")\n",
    "\n",
    "print(\"\\nRAG知识库构建完成！\")\n",
    "print(f\"知识条目: {len(knowledge_base)}\")\n",
    "print(f\"支持实时检索相关法律条文、案例和依据\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM, AutoConfig,\n",
    "    TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig, get_peft_model, TaskType,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "from datasets import Dataset, load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "class LegalLoRATrainer:\n",
    "    \"\"\"劳动合规LoRA微调器 - 修复版本\"\"\"\n",
    "    \n",
    "    def __init__(self, config=LINUX_CONFIG):\n",
    "        self.config = config\n",
    "        self.model_config = config['model_configs'][config['config_type']]\n",
    "        self.lora_config = config['lora_config']\n",
    "        self.training_config = config['training_config']\n",
    "        \n",
    "        self.tokenizer = None\n",
    "        self.model = None\n",
    "        self.peft_model = None\n",
    "        \n",
    "    def load_model_and_tokenizer(self):\n",
    "        \"\"\"加载模型和分词器\"\"\"\n",
    "        print(\"加载基础模型和分词器...\")\n",
    "        \n",
    "        model_name = self.model_config['model_name']\n",
    "        device = self.config['device']\n",
    "        \n",
    "        try:\n",
    "            # 加载分词器\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "                model_name,\n",
    "                trust_remote_code=True,\n",
    "                padding_side='left'\n",
    "            )\n",
    "            \n",
    "            # 设置特殊token\n",
    "            if self.tokenizer.pad_token is None:\n",
    "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "            \n",
    "            # 1) 构建配置，关闭SWA并指定eager\n",
    "            config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)\n",
    "            for key in ['sliding_window', 'sliding_window_size', 'use_sliding_window']:\n",
    "                if hasattr(config, key):\n",
    "                    setattr(config, key, False if key == 'use_sliding_window' else None)\n",
    "            setattr(config, 'attn_implementation', 'eager')\n",
    "            \n",
    "            # 2) 组装加载参数（量化/CPU卸载需在加载前放入）\n",
    "            model_kwargs = {\n",
    "                'trust_remote_code': True,\n",
    "                'device_map': None,  # 训练阶段禁用自动分布，以免与Trainer设备管理冲突\n",
    "                'torch_dtype': torch.float16 if device == 'cuda' else torch.float32,\n",
    "                'low_cpu_mem_usage': True,\n",
    "            }\n",
    "            # 训练阶段不使用4bit量化，避免设备管理冲突；显存不足可尝试8bit或减小batch\n",
    "            \n",
    "            # 3) 仅加载一次模型\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_name,\n",
    "                config=config,\n",
    "                attn_implementation='eager',\n",
    "                **model_kwargs\n",
    "            )\n",
    "            # 显式将模型移动到目标设备\n",
    "            if device in ('cuda', 'cpu'):\n",
    "                self.model.to(device)\n",
    "            \n",
    "            # 4) 加载后再次确保禁用SWA（防止模型内部覆盖）\n",
    "            for key in ['sliding_window', 'sliding_window_size', 'use_sliding_window']:\n",
    "                if hasattr(self.model.config, key):\n",
    "                    setattr(self.model.config, key, False if key == 'use_sliding_window' else None)\n",
    "            if hasattr(self.model, 'generation_config'):\n",
    "                for key in ['sliding_window', 'sliding_window_size', 'use_sliding_window']:\n",
    "                    if hasattr(self.model.generation_config, key):\n",
    "                        setattr(self.model.generation_config, key, False if key == 'use_sliding_window' else None)\n",
    "            \n",
    "            print(f\"模型加载完成: {model_name}\")\n",
    "            \n",
    "            # 显示模型信息\n",
    "            if device == 'cuda':\n",
    "                allocated = torch.cuda.memory_allocated() / 1e9\n",
    "                cached = torch.cuda.memory_reserved() / 1e9\n",
    "                print(f\"GPU内存使用: {allocated:.1f}GB (缓存: {cached:.1f}GB)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"模型加载失败: {e}\")\n",
    "            # 可按需添加备用小模型加载逻辑\n",
    "    \n",
    "    def setup_lora(self):\n",
    "        \"\"\"设置LoRA配置\"\"\"\n",
    "        print(\"配置LoRA微调...\")\n",
    "        \n",
    "        # LoRA配置\n",
    "        lora_config = LoraConfig(\n",
    "            r=self.lora_config['r'],\n",
    "            lora_alpha=self.lora_config['lora_alpha'],\n",
    "            lora_dropout=self.lora_config['lora_dropout'],\n",
    "            target_modules=self.lora_config['target_modules'],\n",
    "            bias=self.lora_config['bias'],\n",
    "            task_type=TaskType.CAUSAL_LM,\n",
    "        )\n",
    "        \n",
    "        # 准备模型进行训练\n",
    "        if self.model_config['use_4bit']:\n",
    "            self.model = prepare_model_for_kbit_training(self.model)\n",
    "        \n",
    "        # 应用LoRA\n",
    "        self.peft_model = get_peft_model(self.model, lora_config)\n",
    "        \n",
    "        # 显示可训练参数\n",
    "        trainable_params = sum(p.numel() for p in self.peft_model.parameters() if p.requires_grad)\n",
    "        total_params = sum(p.numel() for p in self.peft_model.parameters())\n",
    "        \n",
    "        print(f\"LoRA配置完成:\")\n",
    "        print(f\"  可训练参数: {trainable_params:,} ({100 * trainable_params / total_params:.2f}%)\")\n",
    "        print(f\"  总参数: {total_params:,}\")\n",
    "        print(f\"  LoRA秩: {self.lora_config['r']}\")\n",
    "        \n",
    "        return self.peft_model\n",
    "    \n",
    "    def prepare_training_data(self, training_data):\n",
    "        \"\"\"准备训练和验证数据集（聊天模板+仅监督回答段落）\"\"\"\n",
    "        print(\"准备训练和验证数据...\")\n",
    "\n",
    "        def build_chat_sample(instruction: str, response: str) -> str:\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": \"你是经验丰富的劳动法律师，回答要专业、结构化。\"},\n",
    "                {\"role\": \"user\", \"content\": instruction},\n",
    "                {\"role\": \"assistant\", \"content\": response},\n",
    "            ]\n",
    "            if hasattr(self.tokenizer, 'apply_chat_template'):\n",
    "                return self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
    "            # 退化为简易模板\n",
    "            return f\"[系统] 你是经验丰富的劳动法律师。\\n[用户] {instruction}\\n[助手] {response}\"\n",
    "\n",
    "        # 构造训练文本\n",
    "        texts = []\n",
    "        for item in training_data:\n",
    "            instr = f\"请分析以下劳动合同条款的合规风险：\\n{item['input']}\"\n",
    "            resp = item['output']\n",
    "            texts.append(build_chat_sample(instr, resp))\n",
    "\n",
    "        # 划分训练集和验证集\n",
    "        train_texts, val_texts = train_test_split(texts, test_size=0.1, random_state=42)\n",
    "        print(f\"训练集: {len(train_texts)}样本, 验证集: {len(val_texts)}样本\")\n",
    "\n",
    "        def tokenize_with_mask(text: str):\n",
    "            enc = self.tokenizer(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=self.model_config['max_length'],\n",
    "            )\n",
    "            labels = enc[\"input_ids\"][:]\n",
    "            # 简化的回答掩码策略：仅保留最后40%的token为可学习标签\n",
    "            cutoff = int(len(labels) * 0.6)\n",
    "            for i in range(cutoff):\n",
    "                labels[i] = -100\n",
    "            enc[\"labels\"] = labels\n",
    "            return enc\n",
    "\n",
    "        # 创建数据集\n",
    "        train_dataset = Dataset.from_dict({'text': train_texts})\n",
    "        val_dataset = Dataset.from_dict({'text': val_texts})\n",
    "\n",
    "        # 分词（不使用 num_proc=0，避免报错）\n",
    "        train_tokenized = train_dataset.map(lambda x: tokenize_with_mask(x['text']), batched=False, remove_columns=['text'])\n",
    "        val_tokenized   = val_dataset.map(lambda x: tokenize_with_mask(x['text']),   batched=False, remove_columns=['text'])\n",
    "\n",
    "        print(f\"数据准备完成: 训练集 {len(train_tokenized)}, 验证集 {len(val_tokenized)}\")\n",
    "        return train_tokenized, val_tokenized\n",
    "\n",
    "    def train(self, training_data, output_dir=\"./legal_lora_model\"):\n",
    "        \"\"\"开始LoRA训练\"\"\"\n",
    "        print(\"开始LoRA微调训练...\")\n",
    "        \n",
    "        # 准备数据\n",
    "        train_dataset, eval_dataset = self.prepare_training_data(training_data)\n",
    "        \n",
    "        # 训练参数\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            num_train_epochs=self.training_config['num_epochs'],\n",
    "            per_device_train_batch_size=self.model_config['batch_size'],\n",
    "            gradient_accumulation_steps=self.training_config['gradient_accumulation_steps'],\n",
    "            warmup_steps=self.training_config['warmup_steps'],\n",
    "            learning_rate=self.training_config['learning_rate'],\n",
    "            weight_decay=0.05,\n",
    "            logging_dir=f\"{output_dir}/logs\",\n",
    "            logging_steps=10,\n",
    "            eval_strategy=\"steps\",\n",
    "            eval_steps=50,\n",
    "            save_strategy=\"steps\",\n",
    "            save_steps=50,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"eval_loss\",\n",
    "            greater_is_better=False,\n",
    "            fp16=self.training_config['fp16'] and torch.cuda.is_available(),\n",
    "            gradient_checkpointing=self.training_config['gradient_checkpointing'],\n",
    "            dataloader_num_workers=self.training_config['dataloader_num_workers'],\n",
    "            remove_unused_columns=False,\n",
    "            report_to=\"tensorboard\",\n",
    "        )\n",
    "        \n",
    "        # 数据整理器\n",
    "        data_collator = DataCollatorForLanguageModeling(\n",
    "            tokenizer=self.tokenizer,\n",
    "            mlm=False\n",
    "        )\n",
    "        \n",
    "        # 创建训练器\n",
    "        trainer = Trainer(\n",
    "            model=self.peft_model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=eval_dataset,\n",
    "            data_collator=data_collator,\n",
    "            label_names=[\"labels\"],\n",
    "        )\n",
    "        \n",
    "        # 开始训练\n",
    "        print(\"开始训练，利用多线程数据加载和验证...\")\n",
    "        \n",
    "        try:\n",
    "            trainer.train()\n",
    "            \n",
    "            # 保存最好的模型\n",
    "            best_model_path = f\"{output_dir}/best_model\"\n",
    "            trainer.save_model(best_model_path)\n",
    "            self.tokenizer.save_pretrained(best_model_path)\n",
    "            \n",
    "            print(f\"训练完成，最佳模型已保存到: {best_model_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"训练失败: {e}\")\n",
    "        \n",
    "        return trainer\n",
    "\n",
    "# 初始化LoRA训练器\n",
    "print(\"初始化LoRA训练器...\")\n",
    "lora_trainer = LegalLoRATrainer()\n",
    "\n",
    "# 加载模型\n",
    "print(\"加载模型和分词器...\")\n",
    "lora_trainer.load_model_and_tokenizer()\n",
    "\n",
    "# 设置LoRA\n",
    "print(\"设置LoRA配置...\")\n",
    "peft_model = lora_trainer.setup_lora()\n",
    "\n",
    "print(\"\\nLoRA微调模块准备完成！\")\n",
    "print(\"可以继续运行下一个Cell进行RAG+LoRA集成\")\n",
    "print(\"如需训练模型，取消注释下面的代码：\")\n",
    "trainer = lora_trainer.train(training_data, output_dir=\"./legal_lora_model_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import PeftModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
    "import gradio as gr\n",
    "import gc\n",
    "\n",
    "class LegalAnalysisSystem:\n",
    "    \n",
    "    def __init__(self, lora_model_path, rag_system, config=LINUX_CONFIG):\n",
    "        self.config = config\n",
    "        self.device = config['device']\n",
    "        self.tokenizer = None\n",
    "        self.model = None\n",
    "        self.rag_system = rag_system\n",
    "        self.lora_model_path = lora_model_path\n",
    "        \n",
    "        # 加载RAG的嵌入模型\n",
    "        self.rag_system.load_embedding_model()\n",
    "\n",
    "    def load_finetuned_model(self):\n",
    "        \"\"\"加载微调后的LoRA模型\"\"\"\n",
    "        print(f\"从 {self.lora_model_path} 加载微调后的模型...\")\n",
    "\n",
    "        try:\n",
    "            # 加载基础模型的分词器\n",
    "            base_model_name = self.config['model_configs'][self.config['config_type']]['model_name']\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "                self.lora_model_path,\n",
    "                trust_remote_code=True\n",
    "            )\n",
    "\n",
    "            # 加载基础模型\n",
    "            model_kwargs = {\n",
    "                'trust_remote_code': True,\n",
    "                'device_map': 'auto',\n",
    "                'torch_dtype': torch.float16,\n",
    "                'low_cpu_mem_usage': True,\n",
    "            }\n",
    "            if self.config['model_configs'][self.config['config_type']]['use_4bit']:\n",
    "                 from transformers import BitsAndBytesConfig\n",
    "                 bnb_config = BitsAndBytesConfig(\n",
    "                    load_in_4bit=True,\n",
    "                    bnb_4bit_quant_type=\"nf4\",\n",
    "                    bnb_4bit_compute_dtype=torch.float16,\n",
    "                    bnb_4bit_use_double_quant=True,\n",
    "                )\n",
    "                 model_kwargs['quantization_config'] = bnb_config\n",
    "            \n",
    "            base_model = AutoModelForCausalLM.from_pretrained(\n",
    "                base_model_name,\n",
    "                **model_kwargs\n",
    "            )\n",
    "            \n",
    "            # 加载LoRA权重\n",
    "            self.model = PeftModel.from_pretrained(base_model, self.lora_model_path)\n",
    "            self.model = self.model.merge_and_unload() # 合并权重以便于推理\n",
    "            self.model.eval()\n",
    "\n",
    "            print(\"微调模型加载并合并完成！\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"模型加载失败: {e}\")\n",
    "            raise\n",
    "\n",
    "    def analyze_clause(self, clause_text, top_k=3):\n",
    "        \"\"\"分析劳动合同条款\"\"\"\n",
    "        if not self.model or not self.tokenizer:\n",
    "            print(\"模型未加载，请先调用 load_finetuned_model()\")\n",
    "            return \"模型未加载\", \"\"\n",
    "\n",
    "        print(f\"正在分析条款: '{clause_text}'\")\n",
    "        \n",
    "        # 1. 使用RAG检索相关知识\n",
    "        print(\"   - 使用RAG检索相关知识...\")\n",
    "        retrieved_knowledge = self.rag_system.search(clause_text, top_k=top_k)\n",
    "        \n",
    "        knowledge_context = \"\"\n",
    "        if retrieved_knowledge:\n",
    "            print(f\"   - 检索到 {len(retrieved_knowledge)} 条相关知识\")\n",
    "            knowledge_context += \"背景知识：\\n\"\n",
    "            for i, item in enumerate(retrieved_knowledge):\n",
    "                knowledge_context += f\"{i+1}. [来源: {item['type']}] {item['content']}\\n\"\n",
    "        else:\n",
    "            print(\"   - 未检索到直接相关的知识\")\n",
    "\n",
    "        # 2. 构建模型输入\n",
    "        prompt = f\"\"\"\n",
    "[指令]\n",
    "你是一位经验丰富的劳动法律师。请根据以下背景知识，分析劳动合同中的条款是否存在法律风险。\n",
    "\n",
    "背景知识:\n",
    "{knowledge_context if knowledge_context else \"无\"}\n",
    "\n",
    "待分析条款:\n",
    "\"{clause_text}\"\n",
    "\n",
    "请提供详细的风险分析、相关案例（如果有）、法律依据和改进建议。\n",
    "\n",
    "[回答]\n",
    "\"\"\"\n",
    "        \n",
    "        # 3. 模型生成答案\n",
    "        print(\"   - 模型生成分析结果...\")\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        \n",
    "        streamer = TextStreamer(self.tokenizer, skip_prompt=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1024,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "                repetition_penalty=1.1,\n",
    "                do_sample=True,\n",
    "                streamer=streamer,\n",
    "                pad_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # 清理内存\n",
    "        del inputs, outputs\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return response.split('[回答]')[1].strip(), knowledge_context\n",
    "\n",
    "# --- 交互式测试 ---\n",
    "\n",
    "# 假设之前的单元格已经成功运行\n",
    "# lora_trainer, rag_system 已经创建并训练/构建完成\n",
    "\n",
    "# 设置微调模型的路径 (请根据实际情况修改)\n",
    "FINETUNED_MODEL_PATH = \"./legal_lora_model_v2/best_model\" \n",
    "\n",
    "# 初始化分析系统\n",
    "analysis_system = LegalAnalysisSystem(\n",
    "    lora_model_path=FINETUNED_MODEL_PATH,\n",
    "    rag_system=rag_system  # 使用前面构建的RAG系统\n",
    ")\n",
    "\n",
    "# 加载模型\n",
    "try:\n",
    "    analysis_system.load_finetuned_model()\n",
    "    print(\"模型加载成功，可以开始测试。\")\n",
    "except Exception as e:\n",
    "    print(f\"无法加载模型，请确认路径 '{FINETUNED_MODEL_PATH}' 是否正确，并且模型已训练。\")\n",
    "\n",
    "\n",
    "def gradio_interface(clause):\n",
    "    \"\"\"Gradio界面调用的函数\"\"\"\n",
    "    if not analysis_system.model:\n",
    "        return \"模型未成功加载，请检查后台日志。\", \"无\"\n",
    "    \n",
    "    analysis_result, retrieved_info = analysis_system.analyze_clause(clause)\n",
    "    \n",
    "    return analysis_result, retrieved_info\n",
    "\n",
    "# 创建Gradio应用\n",
    "iface = gr.Interface(\n",
    "    fn=gradio_interface,\n",
    "    inputs=gr.Textbox(lines=5, label=\"请输入要分析的劳动合同条款\", placeholder=\"例如：员工同意公司有权根据经营需要，随时调整其工作岗位和工作地点。\"),\n",
    "    outputs=[\n",
    "        gr.Markdown(label=\"模型分析结果\"),\n",
    "        gr.Textbox(lines=8, label=\"RAG检索到的相关知识\", interactive=False)\n",
    "    ],\n",
    "    title=\"智能劳动法合规审查系统\",\n",
    "    description=\"本系统结合了LoRA微调模型和RAG知识库，可以对劳动合同条款进行智能分析，并提供法律依据和案例参考。\",\n",
    "    examples=[\n",
    "        [\"员工试用期为6个月，期间工资为正式工资的60%。\"],\n",
    "        [\"所有员工必须无条件接受加班安排，否则按旷工处理。\"],\n",
    "        [\"员工在职期间产生的所有知识产权，无论是否与工作相关，均归公司所有。\"]\n",
    "    ],\n",
    "    theme=gr.themes.Soft()\n",
    ")\n",
    "\n",
    "# 启动Gradio界面\n",
    "# iface.launch(share=True)\n",
    "print(\"\\n交互式测试单元格准备就绪！\")\n",
    "print(\"如果需要启动Web界面进行测试，请取消最后一行 `iface.launch(share=True)` 的注释并运行。\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
